## 张量并行

> [张量并行](https://github.com/wdndev/llm_interview_note/blob/main/04.%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/4.%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C/4.%E5%BC%A0%E9%87%8F%E5%B9%B6%E8%A1%8C.md)

### 张量并行的概念和原理
张量并行是一种分布式训练技术，它通过**将模型中的张量拆分**并放置到不同的 GPU 上，来解决单块GPU无法储存整个模型的问题。
与传统的模型并行不同，张量并行不是将整个计算图的不同部分分配给不同的设备，而是将计算图中的层内的参数（张量）切分到不同设备，每个设备只拥有模型的一部分，以减少内存负荷。
这种并行方式从数学原理上来看，对于线性层就是把矩阵分块进行计算，然后把结果合并；对于非线性层，则不做额外设计。

### 张量并行的方式
张量并行主要有两种切分方式：行并行和列并行。
行并行是将权重按行分割，同时输入按列分割，这样可以将不同的部分放置在不同的 GPU 上进行计算。
列并行则是将权重按列分割，输入数据则保持不变，通过这种方式，不同的GPU可以并行处理不同的数据列。
这两种方式各有优势，适用于不同的场景和模型结构。

### 1维（1D）张量并行（Megatron-LM）
Megatron-LM 提出了一种高效的一维（1D）张量并行实现，这种并行方式主要针对基于 Transformer 架构的大模型。
在这种方案中，张量按照某一个维度进行划分，主要针对多头注意力（MHA）块和 MLP 块进行切分。
- 对于 MLP 层（该层主要由一个GELU是激活函数，以及 A 和 B 两个线性层组成），先对 A 采用“列切割”，然后对 B 采用“行切割”。
- 对于 MHA 层，对三个参数矩阵Q，K，V，按照“列切割”，每个头放到一块 GPU 上，做并行计算。

这种 1D 张量并行方式虽然有效，但在处理超大模型时，由于每个处理器都需要存储整个中间激活，会消耗大量的显存空间，并且通信成本随并行度增高而激增。

### 多维张量并行
为了解决1维张量并行的局限性，Colossal-AI 提供了多维张量并行方案，包括2D、2.5D和3D张量并行。
2D 张量并行在 SUMMA 算法基础上，将 input 和 weight 沿两个维度均匀切分，这样可以平均分配计算和内存负荷。
2.5D 张量并行在 2D SUMMA 基础上，使用更多的设备来减少通信。
3D 张量并行进一步细粒度划分，以期望获得最佳通信成本优化。
这些多维张量并行方案相比1D张量并行，具有更少的内存和网络通信开销，更适合超大AI模型的需求。

---

Ref: [Tensor Parallelism](https://colossalai.org/docs/features/1D_tensor_parallel)