## 关于微调的讨论

### 为什么 SFT 之后感觉 LLM 傻了
在 Supervised Fine-Tuning（SFT）之后，有时人们可能会感觉到模型性能有所下降或出现“变傻”的现象。
这主要是因为SFT虽然提高了模型在特定任务上的性能，但也可能降低了模型的泛化能力和通用性。

原因分析；
1. **数据集限制**：SFT 通常依赖于特定任务的数据集进行微调，这可能导致模型在训练过程中过于专注于这些任务（若数据集相对较小，则可能发生过拟合），而忽视了其他领域的知识。又或者数据集缺乏多样性，未能涵盖新任务上的各种情况，导致模型在面对新的、与数据集不同的输入时出现有偏差的预测。
2. **模型遗忘**：领域特定数据训练后，通用能力往往会有所下降，这是因为模型在微调过程中可能会遗忘一些通用的知识和特征。
3. **非典型标注**：数据集的标注可能存在错误或不准确的标签，这些错误的标签可能会对模型的性能产生负面影响，导致模型产生“傻”的行为。

缓解措施：
1. **增加数据多样性**：通过增加不同领域和任务的数据，可以提高模型的泛化能力。
2. 仔细检查微调数据集的标注，确保标签的准确性和一致性。
3. 使用正则化技术（如权重衰减、dropout）来减少过拟合的风险。
4. 进行数据增强，通过对微调数据进行一些变换或扩充来增加多样性。
5. 使用更复杂的模型架构或调整模型的超参数，以提高模型的性能和泛化能力。


### 领域模型 Continue Pretrain 数据选取
常见的数据选取方法：
1. **领域相关数据**：收集与目标领域相关的数据。这些数据可以是从互联网上爬取的、来自特定领域的文档或者公司内部的数据等。这样的数据可以提供领域相关的语言和知识，有助于模型在特定领域上的表现。
2. **领域专家标注**：如果有领域专家可用，可以请他们对领域相关的数据进行标注，这样可以提供有监督的数据用于模型的训练。
3. **伪标签**：如果没有领域专家或者标注数据的成本较高，可以使用一些自动化的方法生成伪标签。例如，可以使用预训练的模型对领域相关的数据进行预测，将预测结果作为伪标签，然后使用这些伪标签进行模型的训练。
4. **数据平衡**：在进行数据选取时，需要注意数据的平衡性。如果某个类别的数据样本较少，可以考虑使用数据增强技术或者对该类别进行过采样，以平衡各个类别的数据量。
5. **数据质量控制**：在进行数据选取时，需要对数据的质量进行控制。可以使用一些质量评估指标，如数据的准确性、一致性等，来筛选和过滤数据。
6. **数据预处理**：在进行数据选取之前，可能需要对数据进行一些预处理，如分词、去除停用词、标准化等，以准备好输入模型进行训练。


### 如何缓解模型遗忘的问题
缓解模型遗忘通用能力的方法：
1. **保留通用数据**：在进行领域数据训练时，仍然需要保留一部分通用数据用于模型训练。这样可以确保模型仍然能够学习到通用的语言和知识，从而保持一定的通用能力。
2. **增量学习**：使用增量学习（Incremental Learning）的方法，将领域数据与通用数据逐步交替进行训练。这样可以在学习新领域的同时，保持对通用知识的记忆。
3. **预训练和微调**：在领域数据训练之前，可以使用大规模通用数据进行预训练，获得一个通用的基础模型。然后，在领域数据上进行微调，以适应特定领域的任务。这样可以在保留通用能力的同时，提升领域任务的性能。
4. **强化学习**：使用强化学习的方法，通过给模型设置奖励机制，鼓励模型在领域任务上表现好，同时保持一定的通用能力。
5. **领域适应技术**：使用领域适应技术，如领域自适应（Domain Adaptation）和领域对抗训练（Domain Adversarial Training），帮助模型在不同领域之间进行迁移学习，从而减少遗忘通用能力的问题。
6. **数据重采样**：在进行领域数据训练时，可以使用数据重采样的方法，使得模型在训练过程中能够更多地接触到通用数据，从而缓解遗忘通用能力的问题。


### 领域模型继续预训练，如何在模型在预训练的过程中就学习到更多的知识
以下是一些参考策略：
1. **多任务学习**：在预训练过程中，可以引入多个任务，使得模型能够学习到更多的知识。这些任务可以是领域相关的任务，也可以是通用的语言理解任务。通过同时训练多个任务，模型可以学习到更多的语言规律和知识。
2. **多领域数据**：收集来自不同领域的数据，包括目标领域和其他相关领域的数据。将这些数据混合在一起进行预训练，可以使得模型在不同领域的知识都得到学习和融合。
3. **大规模数据**：使用更大规模的数据进行预训练，可以让模型接触到更多的语言和知识。可以从互联网上爬取大量的文本数据，或者利用公开的语料库进行预训练。
4. **数据增强**：在预训练过程中，可以采用数据增强的技术，如随机遮挡、词替换、句子重组等，来生成更多的训练样本。这样可以增加模型的训练数据量，使其能够学习到更多的知识和语言规律。
5. **自监督学习**：引入自监督学习的方法，通过设计一些自动生成的标签或任务，让模型在无监督的情况下进行预训练。例如，可以设计一个掩码语言模型任务，让模型预测被掩码的词语。这样可以使模型在预训练过程中学习到更多的语言知识。


## 领域模型词表扩增是不是有必要的

领域词表扩增的意义：
1. **提高解码效率**：在很多情况下，词表扩增后，处理相同文本时所需的 token 数量减少，这能让模型在处理文本时更高效地进行编码和解码操作。
2. **增加上下文窗口长度**：词表扩充后，模型能够处理更长的文本输入，从而在需要长文本分析的任务中表现更好。
3. **提升模型对领域内容的理解和生成能力**：特定领域往往包含大量专业术语和行话，通过扩增词表，模型可以更准确地理解和生成领域相关的文本。

领域模型的词表扩增可以有助于提升模型在特定领域任务上的性能，但是否有必要取决于具体的情况。
1. **领域特定词汇**：如果目标领域中存在一些特定的词汇或术语，而这些词汇在通用的预训练模型的词表中没有覆盖到，那么词表扩增就是必要的。通过将这些领域特定的词汇添加到模型的词表中，可以使模型更好地理解和处理这些特定的词汇。
2. **领域特定上下文**：在某些领域任务中，词汇的含义可能会受到特定上下文的影响。例如，在医学领域中，同一个词汇在不同的上下文中可能具有不同的含义。如果领域任务中的上下文与通用预训练模型的训练数据中的上下文有较大差异，那么词表扩增可以帮助模型更好地理解和处理领域特定的上下文。
3. **数据稀缺性**：如果目标领域的训练数据相对较少，而通用预训练模型的词表较大，那么词表扩增可以帮助模型更好地利用预训练模型的知识，并提升在目标领域任务上的性能。


## 指令微调的好处？
指令微调（Instruction Fine-tuning）中，**模型接受指令或约束来生成特定的输出**。好处：
1. **控制生成输出**：指令微调使得模型能够根据指定的指令或约束生成特定的输出。这对于需要精确控制模型生成结果的任务非常有用。
2. **可解释性和可控性**：通过指令微调，可以将任务的要求以指令的形式传达给模型。这增加了模型的可解释性和可控性，使得用户能够更好地理解和干预模型的生成过程。
3. **避免不符合要求的输出**
4. **提供任务性能**：指令微调可以针对具体任务进行优化，使得模型在该任务上的性能得到提升。通过引入任务特定的指令或约束，模型可以更好地适应特定任务的需求，并生成更准确、更合理的输出。
5. **灵活性和可扩展性**：指令微调是一种灵活且可扩展的方法，允许在不同任务和场景中进行微调。通过调整和修改指令或约束，可以适应不同的任务需求，并在多个任务上进行微调。


## 预训练和微调，哪个阶段注入了知识
预训练和微调两个阶段都可以注入知识，注入知识的方式和范围略有不同。
- 预训练阶段：模型通过大规模的未标注数据进行训练，从中学习语言的统计特征、语义知识和语言规律。预训练的目的是让模型建立起**对语言的基本理解和概念**，并学习到一般性的语言表示。这种预训练过程**注入了通用的语言知识，并可以迁移到各种下游任务中**。
- 微调阶段：预训练模型使用带标注的数据进行微调，以适应具体任务的要求。模型通过接触任务特定的数据和标签，进一步调整和优化模型的参数，使其更好地适应任务的特定特征和要求。微调阶段注入的是**与任务相关的知识和信息**。

---

Refs:
- [1.微调.md](https://github.com/wdndev/llm_interview_note/blob/main/05.%E6%9C%89%E7%9B%91%E7%9D%A3%E5%BE%AE%E8%B0%83/1.%E5%BE%AE%E8%B0%83/1.%E5%BE%AE%E8%B0%83.md)
- [SFT指令微调大模型后,感觉LLM变傻了](https://blog.csdn.net/aigchouse/article/details/139511108)
