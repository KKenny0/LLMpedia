
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Lilian-Attention?Attention! · LLMpedia</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="Kenny Wu">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search-pro/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-tbfed-pagefooter/footer.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-pageview-count/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchor-navigation-ex/style/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    前言
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="./">
            
                <a href="./">
            
                    
                    模型结构
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" >
            
                <span>
            
                    
                    基础模型结构
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1" >
            
                <span>
            
                    
                    Transformer 架构
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1.1" data-path="Infrastructure_transformer_transformer-explainer.html">
            
                <a href="Infrastructure_transformer_transformer-explainer.html">
            
                    
                    Transformer 可视化解释
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.1.2" data-path="Infrastructure_luxiangdong_Transformer-OverallArch.html">
            
                <a href="Infrastructure_luxiangdong_Transformer-OverallArch.html">
            
                    
                    土猛的员外-Transformer 架构的整体指南
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.1.2" data-path="Infrastructure_HF_Encoder-models.html">
            
                <a href="Infrastructure_HF_Encoder-models.html">
            
                    
                    Encoder 模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.3" data-path="Infrastructure_HF_Decoder-models.html">
            
                <a href="Infrastructure_HF_Decoder-models.html">
            
                    
                    Decoder 模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.4" data-path="Infrastructure_HF_Encoder-Decoder-models.html">
            
                <a href="Infrastructure_HF_Encoder-Decoder-models.html">
            
                    
                    Encoder-Decoder 模型
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2" >
            
                <span>
            
                    
                    进阶结构
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.1" >
            
                <span>
            
                    
                    注意力机制
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="1.2.2.1.1" data-path="Advanced_Blog_AttentionAttention.html">
            
                <a href="Advanced_Blog_AttentionAttention.html">
            
                    
                    Lilian-Attention?Attention!
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2.2" >
            
                <span>
            
                    
                    框架变体
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../Chap2-TrainingTech/">
            
                <a href="../Chap2-TrainingTech/">
            
                    
                    训练技术
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" >
            
                <span>
            
                    
                    预训练
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" >
            
                <span>
            
                    
                    微调
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.2.1" >
            
                <span>
            
                    
                    监督微调
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.2" >
            
                <span>
            
                    
                    指令微调
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.3" >
            
                <span>
            
                    
                    强化学习
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" >
            
                <span>
            
                    
                    蒸馏和压缩
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.4.1" >
            
                <span>
            
                    
                    知识蒸馏
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.2" >
            
                <span>
            
                    
                    剪枝和量化
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../Chap3-PromptEngr/">
            
                <a href="../Chap3-PromptEngr/">
            
                    
                    Prompt 工程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" >
            
                <span>
            
                    
                    Prompt 技术
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1.1" data-path="../Chap3-PromptEngr/prompt-tech_baoyu_how-to-write-good-prompt.html">
            
                <a href="../Chap3-PromptEngr/prompt-tech_baoyu_how-to-write-good-prompt.html">
            
                    
                    宝玉老师-如何写好提示词？
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4.2" >
            
                <span>
            
                    
                    应用场景
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.2.1" data-path="../Chap3-PromptEngr/prompt-app_openai-prompt-generation.html">
            
                <a href="../Chap3-PromptEngr/prompt-app_openai-prompt-generation.html">
            
                    
                    OpenAI-生成提示词的提示词
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../Chap4-InferAndOpt/">
            
                <a href="../Chap4-InferAndOpt/">
            
                    
                    推理与优化
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" >
            
                <span>
            
                    
                    推理框架
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" >
            
                <span>
            
                    
                    推理加速
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3" >
            
                <span>
            
                    
                    多模态处理
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.1" >
            
                <span>
            
                    
                    图像-文本模型
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2" >
            
                <span>
            
                    
                    跨模态注意力机制
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.4" >
            
                <span>
            
                    
                    内容与计算优化
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../Chap5-App/">
            
                <a href="../Chap5-App/">
            
                    
                    应用方向
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" >
            
                <span>
            
                    
                    文本生成与摘要
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.1" >
            
                <span>
            
                    
                    自然语言生成
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.2" >
            
                <span>
            
                    
                    文本摘要
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2" >
            
                <span>
            
                    
                    问答与对话技术
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1" >
            
                <span>
            
                    
                    Chatbot 技术
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.2" >
            
                <span>
            
                    
                    问答系统与检索增强生成
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.3" >
            
                <span>
            
                    
                    代码生成与分析
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.3.1" >
            
                <span>
            
                    
                    编程助手
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3.2" >
            
                <span>
            
                    
                    自动代码补全
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Lilian-Attention?Attention!</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <html><head></head><body><div id="anchor-navigation-ex-navbar"><i class="fa fa-navicon"></i><ul><ul><li><span class="title-icon "></span><a href="#&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;"><b>1.1. </b>&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;</a></li><li><span class="title-icon "></span><a href="#&#x4E3A;&#x7FFB;&#x8BD1;&#x800C;&#x751F;"><b>1.2. </b>&#x4E3A;&#x7FFB;&#x8BD1;&#x800C;&#x751F;</a></li><li><span class="title-icon "></span><a href="#&#x4E00;&#x7CFB;&#x5217;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;"><b>1.3. </b>&#x4E00;&#x7CFB;&#x5217;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;</a></li><ul><li><span class="title-icon "></span><a href="#&#x6982;&#x62EC;"><b>1.3.1. </b>&#x6982;&#x62EC;</a></li><li><span class="title-icon "></span><a href="#self-attention"><b>1.3.2. </b>Self-Attention</a></li><li><span class="title-icon "></span><a href="#soft-vs-hard-attention"><b>1.3.3. </b>Soft vs Hard Attention</a></li><li><span class="title-icon "></span><a href="#global-vs-local-attention"><b>1.3.4. </b>Global vs Local Attention</a></li></ul></ul></ul></div><a href="#" id="anchorNavigationExGoTop"><i class="fa fa-arrow-up"></i></a><h2 id="&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;"><a name="&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;" class="anchor-navigation-ex-anchor" href="#&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;"><i class="fa fa-link" aria-hidden="true"></i></a>1.1. &#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;</h2>
<blockquote>
<p><a href="https://lilianweng.github.io/posts/2018-06-24-attention/#multi-head-self-attention" target="_blank">Attention? Attention!</a></p>
</blockquote>
<p>&#x7B80;&#x800C;&#x8A00;&#x4E4B;&#xFF0C;&#x6DF1;&#x5EA6;&#x5B66;&#x4E60;&#x4E2D;&#x7684;&#x6CE8;&#x610F;&#x529B;&#x53EF;&#x4EE5;&#x88AB;&#x5E7F;&#x4E49;&#x5730;&#x89E3;&#x91CA;&#x4E3A;&#x91CD;&#x8981;&#x6027;&#x6743;&#x91CD;&#x5411;&#x91CF;&#xFF1A;&#x4E3A;&#x4E86;&#x9884;&#x6D4B;&#x6216;&#x63A8;&#x65AD;&#x4E00;&#x4E2A;&#x5143;&#x7D20;&#xFF0C;&#x4F8B;&#x5982;&#x56FE;&#x50CF;&#x4E2D;&#x7684;&#x4E00;&#x4E2A;&#x50CF;&#x7D20;&#x6216;&#x53E5;&#x5B50;&#x4E2D;&#x7684;&#x4E00;&#x4E2A;&#x5355;&#x8BCD;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x6CE8;&#x610F;&#x529B;&#x5411;&#x91CF;&#x6765;&#x4F30;&#x8BA1;&#x5B83;&#x4E0E;&#x5176;&#x4ED6;&#x5143;&#x7D20;&#x7684;&#x76F8;&#x5173;&#x6027;&#xFF08;&#x6216; &quot;&#x5173;&#x6CE8;&quot;&#xFF0C;&#x60A8;&#x53EF;&#x80FD;&#x5728;&#x8BB8;&#x591A;&#x8BBA;&#x6587;&#x4E2D;&#x8BFB;&#x5230;&#x8FC7;&#xFF09;&#xFF0C;&#x5E76;&#x5C06;&#x5B83;&#x4EEC;&#x7684;&#x503C;&#x4E4B;&#x548C;&#x7ECF;&#x6CE8;&#x610F;&#x529B;&#x5411;&#x91CF;&#x52A0;&#x6743;&#x540E;&#x4F5C;&#x4E3A;&#x76EE;&#x6807;&#x7684;&#x8FD1;&#x4F3C;&#x503C;&#x3002;</p>
<h2 id="&#x4E3A;&#x7FFB;&#x8BD1;&#x800C;&#x751F;"><a name="&#x4E3A;&#x7FFB;&#x8BD1;&#x800C;&#x751F;" class="anchor-navigation-ex-anchor" href="#&#x4E3A;&#x7FFB;&#x8BD1;&#x800C;&#x751F;"><i class="fa fa-link" aria-hidden="true"></i></a>1.2. &#x4E3A;&#x7FFB;&#x8BD1;&#x800C;&#x751F;</h2>
<p>&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;&#x7684;&#x8BDE;&#x751F;&#x662F;&#x4E3A;&#x4E86;&#x5E2E;&#x52A9;&#x795E;&#x7ECF;&#x673A;&#x5668;&#x7FFB;&#x8BD1;&#xFF08;NMT&#xFF09;&#x8BB0;&#x5FC6;&#x957F;&#x53E5;&#x3002;
&#x6CE8;&#x610F;&#x529B;&#x53D1;&#x660E;&#x7684;&#x79D8;&#x8BC0;&#x662F;&#x5728;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x548C;&#x6574;&#x4E2A;&#x6E90;&#x8F93;&#x5165;&#x4E4B;&#x95F4;&#x521B;&#x5EFA;&#x6377;&#x5F84;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x4ECE;&#x7F16;&#x7801;&#x5668;&#x7684;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x9690;&#x85CF;&#x72B6;&#x6001;&#x4E2D;&#x5EFA;&#x7ACB;&#x4E00;&#x4E2A;&#x5355;&#x4E00;&#x7684;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x3002;
&#x8FD9;&#x4E9B;&#x6377;&#x5F84;&#x8FDE;&#x63A5;&#x7684;&#x6743;&#x91CD;&#x53EF;&#x9488;&#x5BF9;&#x6BCF;&#x4E2A;&#x8F93;&#x51FA;&#x5143;&#x7D20;&#x8FDB;&#x884C;&#x5B9A;&#x5236;&#x3002;</p>
<p>&#x867D;&#x7136;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x53EF;&#x4EE5;&#x8BBF;&#x95EE;&#x6574;&#x4E2A;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#xFF0C;&#x4F46;&#x6211;&#x4EEC;&#x4E0D;&#x5FC5;&#x62C5;&#x5FC3;&#x9057;&#x5FD8;&#x95EE;&#x9898;&#x3002;
&#x6E90;&#x4EE3;&#x7801;&#x548C;&#x76EE;&#x6807;&#x4EE3;&#x7801;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x9F50;&#x662F;&#x7531;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x5B66;&#x4E60;&#x548C;&#x63A7;&#x5236;&#x7684;&#x3002;&#x4ECE;&#x672C;&#x8D28;&#x4E0A;&#x8BB2;&#xFF0C;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x9700;&#x8981;&#x6D88;&#x8017;&#x4E09;&#x9879;&#x4FE1;&#x606F;&#xFF1A;</p>
<ul>
<li>&#x7F16;&#x7801;&#x5668;&#x9690;&#x85CF;&#x72B6;&#x6001;</li>
<li>&#x89E3;&#x7801;&#x5668;&#x9690;&#x85CF;&#x72B6;&#x6001;</li>
<li>&#x6E90;&#x548C;&#x76EE;&#x6807;&#x4E4B;&#x95F4;&#x7684;&#x5BF9;&#x9F50;</li>
</ul>
<p><img src="https://lilianweng.github.io/posts/2018-06-24-attention/encoder-decoder-attention.png" alt="The encoder-decoder model with additive attention mechanism in Bahdanau et al., 2015."></p>
<h2 id="&#x4E00;&#x7CFB;&#x5217;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;"><a name="&#x4E00;&#x7CFB;&#x5217;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;" class="anchor-navigation-ex-anchor" href="#&#x4E00;&#x7CFB;&#x5217;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;"><i class="fa fa-link" aria-hidden="true"></i></a>1.3. &#x4E00;&#x7CFB;&#x5217;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;</h2>
<h3 id="&#x6982;&#x62EC;"><a name="&#x6982;&#x62EC;" class="anchor-navigation-ex-anchor" href="#&#x6982;&#x62EC;"><i class="fa fa-link" aria-hidden="true"></i></a>1.3.1. &#x6982;&#x62EC;</h3>
<p>&#x4E0B;&#x9762;&#x662F;&#x51E0;&#x79CD;&#x6D41;&#x884C;&#x7684;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;&#x548C;&#x76F8;&#x5E94;&#x7684;&#x5BF9;&#x9F50;&#x8BC4;&#x5206;&#x51FD;&#x6570;&#x7684;&#x6C47;&#x603B;&#x8868;&#xFF1A;</p>
<table>
<thead>
<tr>
<th style="text-align:left">&#x540D;&#x79F0;</th>
<th style="text-align:center">&#x5BF9;&#x9F50;&#x8BC4;&#x5206;&#x51FD;&#x6570;</th>
<th style="text-align:center">&#x5F15;&#x7528;</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Content-base attention</td>
<td style="text-align:center">$$score(s_t, h_i) = cosine[s_t, h_i]$$</td>
<td style="text-align:center"><a href="https://arxiv.org/abs/1410.5401" target="_blank">Graves2014</a></td>
</tr>
<tr>
<td style="text-align:left">Additive(*)</td>
<td style="text-align:center">$$score(s<em>t, h_i) = v^T_atanh(W_a[s</em>{t-1};h_i]$$</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank">Bahdanau2015</a></td>
</tr>
<tr>
<td style="text-align:left">Location-Base</td>
<td style="text-align:center">$$\alpha_{t,i} = softmax(W_as_t)$$</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank">Luong2015</a></td>
</tr>
<tr>
<td style="text-align:left">General</td>
<td style="text-align:center">$$score(s_t, h_i) = s^T_tW_ah_i$$</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank">Luong2015</a></td>
</tr>
<tr>
<td style="text-align:left">Dot-Product</td>
<td style="text-align:center">$$score(s_t, h_i) = s^T_th_i$$</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank">Luong2015</a></td>
</tr>
<tr>
<td style="text-align:left">Scaled Dot-Product(^)</td>
<td style="text-align:center">$$score(s_t, h_i) = \frac{s^T_th_i}{\sqrt{n}}$$</td>
<td style="text-align:center"><a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank">Xu2015</a></td>
</tr>
</tbody>
</table>
<p>&#x4EE5;&#x4E0B;&#x662F;&#x66F4;&#x5E7F;&#x6CDB;&#x7C7B;&#x522B;&#x7684;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;&#x7684;&#x6458;&#x8981;&#xFF1A;</p>
<table>
<thead>
<tr>
<th style="text-align:left">&#x540D;&#x79F0;</th>
<th style="text-align:center">&#x5BF9;&#x9F50;&#x8BC4;&#x5206;&#x51FD;&#x6570;</th>
<th style="text-align:center">&#x5F15;&#x7528;</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Self-Attention(&amp;)</td>
<td style="text-align:center">&#x5173;&#x8054;&#x540C;&#x4E00;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x7684;&#x4E0D;&#x540C;&#x4F4D;&#x7F6E;&#x3002;&#x7406;&#x8BBA;&#x4E0A;&#xFF0C;&#x81EA;&#x6CE8;&#x610F;&#x529B;&#x53EF;&#x4EE5;&#x91C7;&#x7528;&#x4E0A;&#x8FF0;&#x4EFB;&#x4F55;&#x8BC4;&#x5206;&#x51FD;&#x6570;&#xFF0C;&#x4F46;&#x53EA;&#x9700;&#x5C06;&#x76EE;&#x6807;&#x5E8F;&#x5217;&#x66FF;&#x6362;&#x4E3A;&#x76F8;&#x540C;&#x7684;&#x8F93;&#x5165;&#x5E8F;&#x5217;&#x5373;&#x53EF;&#x3002;</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1601.06733.pdf" target="_blank">Cheng2016</a></td>
</tr>
<tr>
<td style="text-align:left">Global/Soft</td>
<td style="text-align:center">&#x5173;&#x6CE8;&#x6574;&#x4E2A;&#x8F93;&#x5165;&#x72B6;&#x6001;&#x7A7A;&#x95F4;&#x3002;</td>
<td style="text-align:center"><a href="http://proceedings.mlr.press/v37/xuc15.pdf" target="_blank">Xu2015</a></td>
</tr>
<tr>
<td style="text-align:left">Local/Hard</td>
<td style="text-align:center">&#x5173;&#x6CE8;&#x8F93;&#x5165;&#x72B6;&#x6001;&#x7A7A;&#x95F4;&#x90E8;&#x5206;&#xFF1B;&#x5373;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#x7684;&#x4E00;&#x4E2A; patch&#x3002;</td>
<td style="text-align:center"><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank">Luong2015</a></td>
</tr>
</tbody>
</table>
<h3 id="self-attention"><a name="self-attention" class="anchor-navigation-ex-anchor" href="#self-attention"><i class="fa fa-link" aria-hidden="true"></i></a>1.3.2. Self-Attention</h3>
<p>&#x81EA;&#x6CE8;&#x610F;&#x529B;&#xFF0C;&#x4E5F;&#x79F0;&#x4E3A;&#x5185;&#x90E8;&#x6CE8;&#x610F;&#x529B;&#xFF0C;&#x662F;&#x4E00;&#x79CD;&#x5C06;&#x5355;&#x4E2A;&#x5E8F;&#x5217;&#x7684;&#x4E0D;&#x540C;&#x4F4D;&#x7F6E;&#x76F8;&#x5173;&#x8054;&#x7684;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;&#xFF0C;&#x4EE5;&#x4FBF;&#x8BA1;&#x7B97;&#x540C;&#x4E00;&#x5E8F;&#x5217;&#x7684;&#x8868;&#x793A;&#x3002;
&#x5B83;&#x5DF2;&#x88AB;&#x8BC1;&#x660E;&#x5728;&#x673A;&#x5668;&#x9605;&#x8BFB;&#x3001;&#x62BD;&#x8C61;&#x6982;&#x62EC;&#x6216;&#x56FE;&#x50CF;&#x63CF;&#x8FF0;&#x751F;&#x6210;&#x4E2D;&#x975E;&#x5E38;&#x6709;&#x7528;&#x3002;</p>
<p>&#x5728;&#x4E0B;&#x9762;&#x7684;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;&#x81EA;&#x6CE8;&#x610F;&#x529B;&#x673A;&#x5236;&#x4F7F;&#x6211;&#x4EEC;&#x80FD;&#x591F;&#x5B66;&#x4E60;&#x5F53;&#x524D;&#x5355;&#x8BCD;&#x548C;&#x53E5;&#x5B50;&#x524D;&#x4E00;&#x90E8;&#x5206;&#x4E4B;&#x95F4;&#x7684;&#x76F8;&#x5173;&#x6027;&#x3002;
<img src="https://lilianweng.github.io/posts/2018-06-24-attention/cheng2016-fig1.png" alt="The current word is in red and the size of the blue shade indicates the activation level."></p>
<h3 id="soft-vs-hard-attention"><a name="soft-vs-hard-attention" class="anchor-navigation-ex-anchor" href="#soft-vs-hard-attention"><i class="fa fa-link" aria-hidden="true"></i></a>1.3.3. Soft vs Hard Attention</h3>
<p>&#x672C;&#x6587;&#x9996;&#x5148;&#x6839;&#x636E;&#x6CE8;&#x610F;&#x529B;&#x662F;&#x8BBF;&#x95EE;&#x6574;&#x4E2A;&#x56FE;&#x50CF;&#x8FD8;&#x662F;&#x4EC5;&#x8BBF;&#x95EE;&#x4E00;&#x4E2A;&#x8865;&#x4E01;&#xFF0C;&#x63D0;&#x51FA;&#x4E86;&#x201C;&#x8F6F;&#x201D;&#x6CE8;&#x610F;&#x529B;&#x548C;&#x201C;&#x786C;&#x201D;&#x6CE8;&#x610F;&#x529B;&#x4E4B;&#x95F4;&#x7684;&#x533A;&#x522B;&#xFF1A;</p>
<ul>
<li><strong>&#x8F6F;</strong>&#x6CE8;&#x610F;&#x529B;&#xFF1A;&#x5B66;&#x4E60;&#x5BF9;&#x9F50;&#x6743;&#x91CD;&#xFF0C;&#x5E76;&#x5C06;&#x5176; &quot;&#x67D4;&#x548C; &quot;&#x5730;&#x7F6E;&#x4E8E;&#x6E90;&#x56FE;&#x50CF;&#x4E2D;&#x7684;&#x6240;&#x6709;&#x6591;&#x5757;&#x4E0A;&#xFF1B;&#x8FD9;&#x4E0E; <a href="https://arxiv.org/abs/1409.0473" target="_blank">Bahdanau et al., 2015</a> &#x4E2D;&#x7684;&#x5173;&#x6CE8;&#x7C7B;&#x578B;&#x57FA;&#x672C;&#x76F8;&#x540C;&#x3002;<ul>
<li>&#x4F18;&#x70B9;&#xFF1A;&#x6A21;&#x578B;&#x5E73;&#x6ED1;&#x4E14;&#x53EF;&#x5FAE;&#x5206;</li>
<li>&#x7F3A;&#x70B9;&#xFF1A;&#x5F53;&#x6E90;&#x8F93;&#x5165;&#x5F88;&#x5927;&#x65F6;&#xFF0C;&#x6210;&#x672C;&#x6602;&#x8D35;</li>
</ul>
</li>
<li><strong>&#x786C;</strong>&#x6CE8;&#x610F;&#x529B;&#xFF1A;&#x4E00;&#x6B21;&#x53EA;&#x9009;&#x62E9;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x56FE;&#x50CF;&#x7684;&#x4E00;&#x4E2A; patch<ul>
<li>&#x4F18;&#x70B9;&#xFF1A;&#x63A8;&#x7406;&#x65F6;&#x7684;&#x8BA1;&#x7B97;&#x91CF;&#x8F83;&#x5C11;</li>
<li>&#x7F3A;&#x70B9;&#xFF1A;&#x8BE5;&#x6A21;&#x578B;&#x662F;&#x4E0D;&#x53EF;&#x5FAE;&#x5206;&#x7684;&#xFF0C;&#x9700;&#x8981;&#x66F4;&#x590D;&#x6742;&#x7684;&#x6280;&#x672F;&#xFF08;&#x4F8B;&#x5982;&#x65B9;&#x5DEE;&#x51CF;&#x5C11;&#x6216;&#x5F3A;&#x5316;&#x5B66;&#x4E60;&#xFF09;&#x6765;&#x8BAD;&#x7EC3;</li>
</ul>
</li>
</ul>
<h3 id="global-vs-local-attention"><a name="global-vs-local-attention" class="anchor-navigation-ex-anchor" href="#global-vs-local-attention"><i class="fa fa-link" aria-hidden="true"></i></a>1.3.4. Global vs Local Attention</h3>
<p><a href="https://arxiv.org/pdf/1508.04025.pdf" target="_blank">Luong, et al., 2015</a> &#x63D0;&#x51FA;&#x4E86;&#x201C;&#x5168;&#x5C40;&#x201D;&#x548C;&#x201C;&#x5C40;&#x90E8;&#x201D;&#x6CE8;&#x610F;&#x529B;&#x3002;
&#x5168;&#x5C40;&#x6CE8;&#x610F;&#x529B;&#x7C7B;&#x4F3C;&#x4E8E;&#x8F6F;&#x6CE8;&#x610F;&#x529B;&#xFF0C;&#x800C;&#x5C40;&#x90E8;&#x6CE8;&#x610F;&#x529B;&#x662F;&#x786C;&#x6CE8;&#x610F;&#x529B;&#x548C;&#x8F6F;&#x6CE8;&#x610F;&#x529B;&#x7684;&#x6709;&#x8DA3;&#x6DF7;&#x5408;&#xFF0C;&#x662F;&#x5BF9;&#x786C;&#x6CE8;&#x610F;&#x529B;&#x7684;&#x6539;&#x8FDB;&#xFF0C;&#x4F7F;&#x5176;&#x53EF;&#x5FAE;&#x5206;&#xFF1A;&#x6A21;&#x578B;&#x9996;&#x5148;&#x9884;&#x6D4B;&#x5F53;&#x524D;&#x76EE;&#x6807;&#x8BCD;&#x7684;&#x5355;&#x4E00;&#x5BF9;&#x9F50;&#x4F4D;&#x7F6E;&#xFF0C;&#x7136;&#x540E;&#x4F7F;&#x7528;&#x4EE5;&#x6E90;&#x4F4D;&#x7F6E;&#x4E3A;&#x4E2D;&#x5FC3;&#x7684;&#x7A97;&#x53E3;&#x8BA1;&#x7B97;&#x4E0A;&#x4E0B;&#x6587;&#x5411;&#x91CF;&#x3002;</p>
<p><img src="https://lilianweng.github.io/posts/2018-06-24-attention/luong2015-fig2-3.png" alt="Global vs local attention "></p>
<footer class="page-footer"><span class="copyright">Copyright &#xA9; &#x7248;&#x6743;&#x4FE1;&#x606F; all right reserved&#xFF0C;powered by Gitbook</span><span class="footer-modification">&#x8BE5;&#x6587;&#x4EF6;&#x4FEE;&#x8BA2;&#x65F6;&#x95F4;: 
2024-11-14 17:24:41
</span></footer></body></html>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Lilian-Attention?Attention!","level":"1.2.2.1.1","depth":4,"next":{"title":"框架变体","level":"1.2.2.2","depth":3,"ref":"","articles":[]},"previous":{"title":"注意力机制","level":"1.2.2.1","depth":3,"ref":"","articles":[{"title":"Lilian-Attention?Attention!","level":"1.2.2.1.1","depth":4,"path":"Chap1-ModelArch/Advanced_Blog_AttentionAttention.md","ref":"Chap1-ModelArch/Advanced_Blog_AttentionAttention.md","articles":[]}]},"dir":"ltr"},"config":{"plugins":["-lunr","-search","search-pro","back-to-top-button","expandable-chapters","chapter-fold","splitter","code","github","tbfed-pagefooter","pageview-count","copy-code-button","anchor-navigation-ex"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"tbfed-pagefooter":{"copyright":"Copyright &copy 版权信息","modify_label":"该文件修订时间: ","modify_format":"YYYY-MM-DD HH:mm:ss"},"chapter-fold":{},"github":{"url":"https://github.com/KKenny0/LLMpedia"},"splitter":{},"search-pro":{},"code":{"copyButtons":true},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"anchor-navigation-ex":{"showLevel":true,"associatedWithSummary":true,"mode":"float","showGoTop":true,"printLog":false,"multipleH1":true,"float":{"floatIcon":"fa fa-navicon","showLevelIcon":false,"level1Icon":"","level2Icon":"","level3Icon":""},"pageTop":{"showLevelIcon":false,"level1Icon":"","level2Icon":"","level3Icon":""}},"back-to-top-button":{},"pageview-count":{},"copy-code-button":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"expandable-chapters":{}},"theme":"default","keywords":"AI,LLM,笔记","author":"Kenny Wu","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"LLMpedia","introduction":{"path":"README.md","title":"LLMpedia"},"gitbook":"*","description":"搜集和分享个人喜欢的大语言模型（LLM）相关资源的在线百科全书。"},"file":{"path":"Chap1-ModelArch/Advanced_Blog_AttentionAttention.md","mtime":"2024-11-14T09:24:41.412Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2024-11-14T09:26:12.362Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/jquery.mark.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search-pro/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-expandable-chapters/expandable-chapters.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-chapter-fold/chapter-fold.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-pageview-count/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-copy-code-button/toggle.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

